{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c018277",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<center> <h1> BUSINESS CASES WITH DATA SCIENCE </h1> </center> <br>\n",
    "<center> Business Case 5: Cryptocurrency Data Visualization </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f27037",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"group\">\n",
    "    \n",
    "### Group\n",
    "    \n",
    "</a>\n",
    "\n",
    "- Celso Christiano Endres Neto\t\t    |   m20200739 <br>\n",
    "- Gabriel Felipe Martins de Souza   \t|   m20210598 <br>\n",
    "- Luiz Humberto Polaro Vizeu\t\t    |   m20210554 <br>\n",
    "- Rogerio Domingos Paulo\t        \t|   m20210597 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9446757c",
   "metadata": {},
   "source": [
    "**Table of Contents** <br>\n",
    "* [1.0 Import](#import)\n",
    "    * [1.1 Import Libs](#libs)\n",
    "* [2.0 Time Series (Box-Jenkins)](#timeseries)\n",
    "* [3.0 Time Series Data Preparation and Preprocessing](#data_prep_ts)\n",
    "* [4.0 Time Series Model and Assessment](#ts_modeling)\n",
    "* [5.0 Machine Learning](#ml)\n",
    "* [6.0 ML Data Preparation and Preprocessing](#data_prep_ml)\n",
    "* [7.0 Machine Learning Model and Assessment](#ml_modeling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3314052e",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"import\">\n",
    "    \n",
    "# 1.0 Import\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf238f",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"libs\">\n",
    "    \n",
    "## 1.1 Import Libs\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "157b75de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#common packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from math import ceil, pi, sqrt\n",
    "import os\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#!pip install  holidays\n",
    "import holidays\n",
    "import itertools\n",
    "\n",
    "#dataviz\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "import graphviz\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "#algorithms for data preparation and preprocessing\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "# !pip install ta\n",
    "import ta\n",
    "from ta import add_all_ta_features\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "#Modeling and Assessment\n",
    "from sklearn import datasets, linear_model\n",
    "#!pip install XGBoost\n",
    "from sklearn.metrics import mean_squared_error as MSE, r2_score, mean_absolute_percentage_error as MAPE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#Time Series and Modeling\n",
    "#!pip install pmdarima\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.statespace.tools import diff\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "#importing stock data from Yahoo Finance\n",
    "#!pip install yahoo-finance\n",
    "import yfinance as yf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fa7e4a",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"timeseries\">\n",
    "    \n",
    "# 2.0 Time Series (Box_Jenkins)\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb4ced1",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"data_prep_ts\">\n",
    "    \n",
    "# 3.0 Time Series Data Preparation and Preprocessing\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddab1ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of crptocurrencies as ticker arguments\n",
    "cryptocurrencies = ['ADA-USD', 'ATOM-USD', 'AVAX-USD', 'AXS-USD', 'BTC-USD', 'ETH-USD',\n",
    "                     'LINK-USD', 'LUNA1-USD', 'MATIC-USD', 'SOL-USD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce51d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  10 of 10 completed\n"
     ]
    }
   ],
   "source": [
    "##importing data from yahoo finance lib\n",
    "data = yf.download(cryptocurrencies, period = '365d', interval = '1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a429c369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing each indicator in separately dataframe\n",
    "df_open = data['Open'].reset_index()\n",
    "\n",
    "df_close = data['Close'].reset_index()\n",
    "\n",
    "df_adj_close = data['Adj Close'].reset_index()\n",
    "\n",
    "df_high = data['High'].reset_index()\n",
    "\n",
    "df_low = data['Low'].reset_index()\n",
    "\n",
    "df_volume = data['Volume'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccdcfe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list with all the currencies\n",
    "list_of_currencys = df_volume.iloc[:,1:].columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55047dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "\n",
    "for currency in list_of_currencys:\n",
    "    \n",
    "    df[currency] = pd.DataFrame()\n",
    "\n",
    "    #retrieving open price\n",
    "    df1 = df_open[['Date',currency]].copy()\n",
    "    #filtering only non-null records\n",
    "    df1 = df1[~df1[currency].isnull()].copy()\n",
    "    #renaming column ETH-USD to open, which means the Open price for the currency\n",
    "    df1.rename(columns={currency: \"open\"}, inplace=True)\n",
    "\n",
    "    #retrieving close price\n",
    "    df2 = df_close[['Date',currency]]\n",
    "    #filtering only non-null records\n",
    "    df2 = df2[~df2[currency].isnull()].copy()\n",
    "    #renaming column ETH-USD to close, which means the Open price for the currency\n",
    "    df2.rename(columns={currency: \"close\"}, inplace=True)\n",
    "\n",
    "    #retrieving adj_close price\n",
    "    df3 = df_adj_close[['Date',currency]]\n",
    "    #filtering only non-null records\n",
    "    df3 = df3[~df3[currency].isnull()].copy()\n",
    "    #renaming column ETH-USD to adj_close, which means the adj_close price for the currency\n",
    "    df3.rename(columns={currency: \"adj_close\"}, inplace=True)\n",
    "\n",
    "    #retrieving highest price\n",
    "    df4 = df_high[['Date',currency]]\n",
    "    #filtering only non-null records\n",
    "    df4 = df4[~df4[currency].isnull()].copy()\n",
    "    #renaming column ETH-USD to high, which means the highest price for the currency\n",
    "    df4.rename(columns={currency: \"high\"}, inplace=True)\n",
    "\n",
    "    #retrieving lowest price\n",
    "    df5 = df_low[['Date',currency]]\n",
    "    #filtering only non-null records\n",
    "    df5 = df5[~df5[currency].isnull()].copy()\n",
    "    #renaming column ETH-USD to df5, which means the lowest price for the currency\n",
    "    df5.rename(columns={currency: \"low\"}, inplace=True)\n",
    "\n",
    "    #retrieving Volume\n",
    "    df6 = df_volume[['Date',currency]]\n",
    "    #filtering only non-null records\n",
    "    df6 = df6[~df6[currency].isnull()].copy()\n",
    "    #renaming column ETH-USD to Volume, which means the Volume for the currency\n",
    "    df6.rename(columns={currency: \"volume\"}, inplace=True)\n",
    "    \n",
    "    name=str(currency)\n",
    "\n",
    "    #merging dataframes into a single dataframe\n",
    "    temp_2 = pd.merge(df1, df2, left_on='Date', right_on='Date', how='left')\n",
    "    temp_3 = pd.merge(temp_2, df3, left_on='Date', right_on='Date', how='left')\n",
    "    temp_4 = pd.merge(temp_3, df4, left_on='Date', right_on='Date', how='left')\n",
    "    temp_5 = pd.merge(temp_4, df5, left_on='Date', right_on='Date', how='left')\n",
    "    temp_6 = pd.merge(temp_5, df6, left_on='Date', right_on='Date', how='left')    \n",
    "    df[currency] = temp_6.copy()\n",
    "    df[currency]['Date'] = pd.to_datetime(df[currency]['Date'])\n",
    "    df[currency]['volume'] = df[currency]['volume'].astype('Int64')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1e81bd",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"ts_modeling\">\n",
    "    \n",
    "# 4.0 Time Series Model and Assessment\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd56e42",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"BTC-USD\">\n",
    "    \n",
    "## BTC-USD\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6021b15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating a df to predict the crypto currency\n",
    "dfbtc = df['BTC-USD'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "424ad2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new feature for better representing day-wise values\n",
    "dfbtc['mean'] = (dfbtc['low'] + dfbtc['high'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24818cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data for any NaN or Null fields\n",
    "dfbtc = dfbtc.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17333338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy for applying shift\n",
    "dataset_for_prediction = dfbtc.copy()\n",
    "dataset_for_prediction['Actual']=dataset_for_prediction['close'].shift()\n",
    "dataset_for_prediction=dataset_for_prediction.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8eebaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date time typecast\n",
    "dataset_for_prediction['Date'] =pd.to_datetime(dataset_for_prediction['Date'])\n",
    "dataset_for_prediction.index= dataset_for_prediction['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8088a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the exogeneous variables\n",
    "sc_in = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_input = sc_in.fit_transform(dataset_for_prediction[['volume']])  #['low', 'high', 'open', 'adj_close', 'volume', 'mean']\n",
    "scaled_input = pd.DataFrame(scaled_input, index=dataset_for_prediction.index)\n",
    "X=scaled_input\n",
    "X.rename(columns={0:'Volume'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a7d2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the time series\n",
    "sc_out = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_output = sc_out.fit_transform(dataset_for_prediction[['Actual']])\n",
    "scaler_output =pd.DataFrame(scaler_output, index=dataset_for_prediction.index)\n",
    "y=scaler_output\n",
    "y.rename(columns={0:'Observed Data'}, inplace= True)\n",
    "y.index=dataset_for_prediction.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "156227ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split (cannot shuffle in case of time series)\n",
    "train_X, train_y = X[:-7].dropna(), y[:-7].dropna()\n",
    "test_X, test_y = X[-9:].dropna(), y[-8:].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04225146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel.souza_ifood\\anaconda3\\envs\\data-mining-env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\gabriel.souza_ifood\\anaconda3\\envs\\data-mining-env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "# Init the best SARIMAX model\n",
    "model = SARIMAX(\n",
    "    train_y,\n",
    "    exog=train_X,\n",
    "    order=(0,1,0),\n",
    "    seasonal_order =(2, 1, 0, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69d0e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a1de6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "predictions = results.predict(start= len(train_y), end= len(train_y)+len(test_y), exog = test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b2611b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecast\n",
    "fcst = results.predict(start= len(train_y), end= len(train_y)+len(test_y), exog = test_X).to_frame()\n",
    "fcst2 = sc_out.inverse_transform(fcst)\n",
    "#storing the predictions in a dataframe\n",
    "btc_predictions = pd.DataFrame(fcst2, index = fcst.index, columns = ['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6fef58",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"ETH-USD\">\n",
    "    \n",
    "## ETH-USD\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec29bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a df to predict the crypto currency\n",
    "dfeth = df['ETH-USD'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb436d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new feature for better representing day-wise values\n",
    "dfeth['mean'] = (dfeth['low'] + dfeth['high'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27133223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data for any NaN or Null fields\n",
    "dfeth = dfeth.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6bb3973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy for applying shift\n",
    "dataset_for_prediction = dfeth.copy()\n",
    "dataset_for_prediction['Actual']=dataset_for_prediction['close'].shift()\n",
    "dataset_for_prediction=dataset_for_prediction.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9b6bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date time typecast\n",
    "dataset_for_prediction['Date'] =pd.to_datetime(dataset_for_prediction['Date'])\n",
    "dataset_for_prediction.index= dataset_for_prediction['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b792e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the exogeneous variables\n",
    "sc_in = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_input = sc_in.fit_transform(dataset_for_prediction[['volume']])  #['low', 'high', 'open', 'adj_close', 'volume', 'mean']\n",
    "scaled_input = pd.DataFrame(scaled_input, index=dataset_for_prediction.index)\n",
    "X=scaled_input\n",
    "X.rename(columns={0:'Volume'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b007ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the time series\n",
    "sc_out = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_output = sc_out.fit_transform(dataset_for_prediction[['Actual']])\n",
    "scaler_output =pd.DataFrame(scaler_output, index=dataset_for_prediction.index)\n",
    "y=scaler_output\n",
    "y.rename(columns={0:'Observed Data'}, inplace= True)\n",
    "y.index=dataset_for_prediction.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c39ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split (cannot shuffle in case of time series)\n",
    "train_X, train_y = X[:-7].dropna(), y[:-7].dropna()\n",
    "test_X, test_y = X[-9:].dropna(), y[-8:].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e564f507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel.souza_ifood\\anaconda3\\envs\\data-mining-env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\gabriel.souza_ifood\\anaconda3\\envs\\data-mining-env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "# Init the best SARIMAX model\n",
    "model = SARIMAX(\n",
    "    train_y,\n",
    "    exog=train_X,\n",
    "    order=(1,1,0),\n",
    "    seasonal_order =(2, 1, 0, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18a90141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "116e5f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "predictions = results.predict(start= len(train_y), end= len(train_y)+len(test_y), exog = test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad050071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecast\n",
    "fcst = results.predict(start= len(train_y), end= len(train_y)+len(test_y), exog = test_X).to_frame()\n",
    "fcst2 = sc_out.inverse_transform(fcst)\n",
    "#storing the predictions in a dataframe\n",
    "eth_predictions = pd.DataFrame(fcst2, index = fcst.index, columns = ['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a2fdf",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"LINK-USD\">\n",
    "    \n",
    "## LINK-USD\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ac28c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a df to predict the crypto currency\n",
    "dflink = df['LINK-USD'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90b71922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new feature for better representing day-wise values\n",
    "dflink['mean'] = (dflink['low'] + dflink['high'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61426472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data for any NaN or Null fields\n",
    "dflink = dflink.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4e03a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy for applying shift\n",
    "dataset_for_prediction = dflink.copy()\n",
    "dataset_for_prediction['Actual']=dataset_for_prediction['close'].shift()\n",
    "dataset_for_prediction=dataset_for_prediction.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4224dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date time typecast\n",
    "dataset_for_prediction['Date'] =pd.to_datetime(dataset_for_prediction['Date'])\n",
    "dataset_for_prediction.index= dataset_for_prediction['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e97f8d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the exogeneous variables\n",
    "sc_in = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_input = sc_in.fit_transform(dataset_for_prediction[['volume']])  #['low', 'high', 'open', 'adj_close', 'volume', 'mean']\n",
    "scaled_input = pd.DataFrame(scaled_input, index=dataset_for_prediction.index)\n",
    "X=scaled_input\n",
    "X.rename(columns={0:'Volume'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7baf50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the time series\n",
    "sc_out = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_output = sc_out.fit_transform(dataset_for_prediction[['Actual']])\n",
    "scaler_output =pd.DataFrame(scaler_output, index=dataset_for_prediction.index)\n",
    "y=scaler_output\n",
    "y.rename(columns={0:'Observed Data'}, inplace= True)\n",
    "y.index=dataset_for_prediction.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71d45958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split (cannot shuffle in case of time series)\n",
    "train_X, train_y = X[:-7].dropna(), y[:-7].dropna()\n",
    "test_X, test_y = X[-9:].dropna(), y[-8:].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28d18a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel.souza_ifood\\anaconda3\\envs\\data-mining-env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\gabriel.souza_ifood\\anaconda3\\envs\\data-mining-env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "# Init the best SARIMAX model\n",
    "model = SARIMAX(\n",
    "    train_y,\n",
    "    exog=train_X,\n",
    "    order=(1,1,1),\n",
    "    seasonal_order =(2, 1, 0, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7df8d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e1b77d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "predictions = results.predict(start= len(train_y), end= len(train_y)+len(test_y), exog = test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6070d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecast\n",
    "fcst = results.predict(start= len(train_y), end= len(train_y)+len(test_y), exog = test_X).to_frame()\n",
    "fcst2 = sc_out.inverse_transform(fcst)\n",
    "#storing the predictions in a dataframe\n",
    "link_predictions = pd.DataFrame(fcst2, index = fcst.index, columns = ['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189dc292",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"MATIC-USD\">\n",
    "    \n",
    "## MATIC-USD\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e20a11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a df to predict the crypto currency\n",
    "dfmatic = df['MATIC-USD'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e2e2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new feature for better representing day-wise values\n",
    "dfmatic['mean'] = (dfmatic['low'] + dfmatic['high'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c147971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data for any NaN or Null fields\n",
    "dfmatic = dfmatic.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbfcd9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy for applying shift\n",
    "dataset_for_prediction = dfmatic.copy()\n",
    "dataset_for_prediction['Actual']=dataset_for_prediction['close'].shift()\n",
    "dataset_for_prediction=dataset_for_prediction.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8ae683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date time typecast\n",
    "dataset_for_prediction['Date'] =pd.to_datetime(dataset_for_prediction['Date'])\n",
    "dataset_for_prediction.index= dataset_for_prediction['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99cacc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the exogeneous variables\n",
    "sc_in = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_input = sc_in.fit_transform(dataset_for_prediction[['volume']])  #['low', 'high', 'open', 'adj_close', 'volume', 'mean']\n",
    "scaled_input = pd.DataFrame(scaled_input, index=dataset_for_prediction.index)\n",
    "X=scaled_input\n",
    "X.rename(columns={0:'Volume'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61cb9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the time series\n",
    "sc_out = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_output = sc_out.fit_transform(dataset_for_prediction[['Actual']])\n",
    "scaler_output =pd.DataFrame(scaler_output, index=dataset_for_prediction.index)\n",
    "y=scaler_output\n",
    "y.rename(columns={0:'Observed Data'}, inplace= True)\n",
    "y.index=dataset_for_prediction.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0cd94f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split (cannot shuffle in case of time series)\n",
    "train_X, train_y = X[:-7].dropna(), y[:-7].dropna()\n",
    "test_X, test_y = X[-9:].dropna(), y[-8:].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "776e285a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel.souza_ifood\\anaconda3\\envs\\data-mining-env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\gabriel.souza_ifood\\anaconda3\\envs\\data-mining-env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "# Init the best SARIMAX model\n",
    "model = SARIMAX(\n",
    "    train_y,\n",
    "    exog=train_X,\n",
    "    order=(2,1,2),\n",
    "    seasonal_order =(2, 1, 0, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b78aaa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel.souza_ifood\\anaconda3\\envs\\data-mining-env\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a12a2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "predictions = results.predict(start= len(train_y), end= len(train_y)+len(test_y), exog = test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8ef325e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecast\n",
    "fcst = results.predict(start= len(train_y), end= len(train_y)+len(test_y), exog = test_X).to_frame()\n",
    "fcst2 = sc_out.inverse_transform(fcst)\n",
    "#storing the predictions in a dataframe\n",
    "matic_predictions = pd.DataFrame(fcst2, index = fcst.index, columns = ['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4658848c",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"SOL-USD\">\n",
    "    \n",
    "## SOL-USD\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d6757a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a df to predict the crypto currency\n",
    "dfsol = df['SOL-USD'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6952daee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new feature for better representing day-wise values\n",
    "dfsol['mean'] = (dfsol['low'] + dfsol['high'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a54aaa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data for any NaN or Null fields\n",
    "dfsol = dfsol.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4594c1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy for applying shift\n",
    "dataset_for_prediction = dfsol.copy()\n",
    "dataset_for_prediction['Actual']=dataset_for_prediction['close'].shift()\n",
    "dataset_for_prediction=dataset_for_prediction.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "227e19c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date time typecast\n",
    "dataset_for_prediction['Date'] =pd.to_datetime(dataset_for_prediction['Date'])\n",
    "dataset_for_prediction.index= dataset_for_prediction['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c4a55a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the exogeneous variables\n",
    "sc_in = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_input = sc_in.fit_transform(dataset_for_prediction[['volume']])  #['low', 'high', 'open', 'adj_close', 'volume', 'mean']\n",
    "scaled_input = pd.DataFrame(scaled_input, index=dataset_for_prediction.index)\n",
    "X=scaled_input\n",
    "X.rename(columns={0:'Volume'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "970e8c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the time series\n",
    "sc_out = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_output = sc_out.fit_transform(dataset_for_prediction[['Actual']])\n",
    "scaler_output =pd.DataFrame(scaler_output, index=dataset_for_prediction.index)\n",
    "y=scaler_output\n",
    "y.rename(columns={0:'Observed Data'}, inplace= True)\n",
    "y.index=dataset_for_prediction.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e03b60c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split (cannot shuffle in case of time series)\n",
    "train_X, train_y = X[:-7].dropna(), y[:-7].dropna()\n",
    "test_X, test_y = X[-9:].dropna(), y[-8:].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e0b06ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriel.souza_ifood\\anaconda3\\envs\\data-mining-env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\gabriel.souza_ifood\\anaconda3\\envs\\data-mining-env\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "# Init the best SARIMAX model\n",
    "model = SARIMAX(\n",
    "    train_y,\n",
    "    exog=train_X,\n",
    "    order=(0,1,0),\n",
    "    seasonal_order =(2, 1, 0, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c41a3547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe3965bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "predictions = results.predict(start= len(train_y), end= len(train_y)+len(test_y), exog = test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8c46c83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecast\n",
    "fcst = results.predict(start= len(train_y), end= len(train_y)+len(test_y), exog = test_X).to_frame()\n",
    "fcst2 = sc_out.inverse_transform(fcst)\n",
    "#storing the predictions in a dataframe\n",
    "sol_predictions = pd.DataFrame(fcst2, index = fcst.index, columns = ['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f82e22",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"ts_predictions\">\n",
    "    \n",
    "##  Time Series Predictions Summary\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7f19cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #creating dataframes for each currency to summarize the predictions\n",
    "\n",
    "btc_predictions.index.name = 'Date'\n",
    "btc = btc_predictions.rename(columns={'price': 'BTC-USD'}).reset_index()\n",
    "\n",
    "eth_predictions.index.name = 'Date'\n",
    "eth = eth_predictions.rename(columns={'price': 'ETH-USD'}).reset_index()\n",
    "\n",
    "link_predictions.index.name = 'Date'\n",
    "link = link_predictions.rename(columns={'price': 'LINK-USD'}).reset_index()\n",
    "\n",
    "matic_predictions.index.name = 'Date'\n",
    "matic = matic_predictions.rename(columns={'price': 'MATIC-USD'}).reset_index()\n",
    "\n",
    "sol_predictions.index.name = 'Date'\n",
    "sol = sol_predictions.rename(columns={'price': 'SOL-USD'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ed3aecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_a = pd.merge(btc, link, left_on='Date', right_on='Date', how='inner')\n",
    "temp_b = pd.merge(temp_a, matic, left_on='Date', right_on='Date', how='inner')\n",
    "temp_c = pd.merge(temp_b, eth, left_on='Date', right_on='Date', how='inner')\n",
    "final_predictions = pd.merge(temp_c, sol, left_on='Date', right_on='Date', how='inner') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8605ac4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>LINK-USD</th>\n",
       "      <th>MATIC-USD</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>SOL-USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>29800.632089</td>\n",
       "      <td>7.209214</td>\n",
       "      <td>0.701169</td>\n",
       "      <td>2011.888513</td>\n",
       "      <td>51.188797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>28274.342732</td>\n",
       "      <td>6.439757</td>\n",
       "      <td>0.595602</td>\n",
       "      <td>1888.637531</td>\n",
       "      <td>46.128928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>27753.700020</td>\n",
       "      <td>6.112968</td>\n",
       "      <td>0.543988</td>\n",
       "      <td>1780.631535</td>\n",
       "      <td>41.077769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>28129.833892</td>\n",
       "      <td>6.223086</td>\n",
       "      <td>0.569707</td>\n",
       "      <td>1812.436500</td>\n",
       "      <td>42.066936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>27495.929277</td>\n",
       "      <td>5.998551</td>\n",
       "      <td>0.574621</td>\n",
       "      <td>1764.853387</td>\n",
       "      <td>40.429657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>26699.953242</td>\n",
       "      <td>5.602997</td>\n",
       "      <td>0.558048</td>\n",
       "      <td>1709.550838</td>\n",
       "      <td>38.299471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>26598.498519</td>\n",
       "      <td>5.593469</td>\n",
       "      <td>0.584127</td>\n",
       "      <td>1717.542988</td>\n",
       "      <td>38.646213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>25531.469277</td>\n",
       "      <td>4.847741</td>\n",
       "      <td>0.506455</td>\n",
       "      <td>1603.798802</td>\n",
       "      <td>31.533355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>24830.131260</td>\n",
       "      <td>4.384801</td>\n",
       "      <td>0.445702</td>\n",
       "      <td>1472.218447</td>\n",
       "      <td>25.654512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       BTC-USD  LINK-USD  MATIC-USD      ETH-USD    SOL-USD\n",
       "0 2022-05-23  29800.632089  7.209214   0.701169  2011.888513  51.188797\n",
       "1 2022-05-24  28274.342732  6.439757   0.595602  1888.637531  46.128928\n",
       "2 2022-05-25  27753.700020  6.112968   0.543988  1780.631535  41.077769\n",
       "3 2022-05-26  28129.833892  6.223086   0.569707  1812.436500  42.066936\n",
       "4 2022-05-27  27495.929277  5.998551   0.574621  1764.853387  40.429657\n",
       "5 2022-05-28  26699.953242  5.602997   0.558048  1709.550838  38.299471\n",
       "6 2022-05-29  26598.498519  5.593469   0.584127  1717.542988  38.646213\n",
       "7 2022-05-30  25531.469277  4.847741   0.506455  1603.798802  31.533355\n",
       "8 2022-05-31  24830.131260  4.384801   0.445702  1472.218447  25.654512"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "685bc867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataframe to store the predictions for D+1 and D+2 of each currency\n",
    "df_pred_final = final_predictions[-2:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f39c878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>LINK-USD</th>\n",
       "      <th>MATIC-USD</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>SOL-USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>25531.469277</td>\n",
       "      <td>4.847741</td>\n",
       "      <td>0.506455</td>\n",
       "      <td>1603.798802</td>\n",
       "      <td>31.533355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>24830.131260</td>\n",
       "      <td>4.384801</td>\n",
       "      <td>0.445702</td>\n",
       "      <td>1472.218447</td>\n",
       "      <td>25.654512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       BTC-USD  LINK-USD  MATIC-USD      ETH-USD    SOL-USD\n",
       "7 2022-05-30  25531.469277  4.847741   0.506455  1603.798802  31.533355\n",
       "8 2022-05-31  24830.131260  4.384801   0.445702  1472.218447  25.654512"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f6365e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataframe to store the predictions for the validation data\n",
    "df_val_final = final_predictions[:-2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0668945e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>LINK-USD</th>\n",
       "      <th>MATIC-USD</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>SOL-USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>29800.632089</td>\n",
       "      <td>7.209214</td>\n",
       "      <td>0.701169</td>\n",
       "      <td>2011.888513</td>\n",
       "      <td>51.188797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>28274.342732</td>\n",
       "      <td>6.439757</td>\n",
       "      <td>0.595602</td>\n",
       "      <td>1888.637531</td>\n",
       "      <td>46.128928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>27753.700020</td>\n",
       "      <td>6.112968</td>\n",
       "      <td>0.543988</td>\n",
       "      <td>1780.631535</td>\n",
       "      <td>41.077769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>28129.833892</td>\n",
       "      <td>6.223086</td>\n",
       "      <td>0.569707</td>\n",
       "      <td>1812.436500</td>\n",
       "      <td>42.066936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>27495.929277</td>\n",
       "      <td>5.998551</td>\n",
       "      <td>0.574621</td>\n",
       "      <td>1764.853387</td>\n",
       "      <td>40.429657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>26699.953242</td>\n",
       "      <td>5.602997</td>\n",
       "      <td>0.558048</td>\n",
       "      <td>1709.550838</td>\n",
       "      <td>38.299471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>26598.498519</td>\n",
       "      <td>5.593469</td>\n",
       "      <td>0.584127</td>\n",
       "      <td>1717.542988</td>\n",
       "      <td>38.646213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       BTC-USD  LINK-USD  MATIC-USD      ETH-USD    SOL-USD\n",
       "0 2022-05-23  29800.632089  7.209214   0.701169  2011.888513  51.188797\n",
       "1 2022-05-24  28274.342732  6.439757   0.595602  1888.637531  46.128928\n",
       "2 2022-05-25  27753.700020  6.112968   0.543988  1780.631535  41.077769\n",
       "3 2022-05-26  28129.833892  6.223086   0.569707  1812.436500  42.066936\n",
       "4 2022-05-27  27495.929277  5.998551   0.574621  1764.853387  40.429657\n",
       "5 2022-05-28  26699.953242  5.602997   0.558048  1709.550838  38.299471\n",
       "6 2022-05-29  26598.498519  5.593469   0.584127  1717.542988  38.646213"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a30bb2",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"ml\">\n",
    "    \n",
    "# 5.0 Machine Learning\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4df9ae",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"data_prep_ml\">\n",
    "    \n",
    "# 6.0 Data Preparation and Preprocessing\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e77b38a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  10 of 10 completed\n"
     ]
    }
   ],
   "source": [
    "#importing data from yahoo finance lib\n",
    "data = yf.download(cryptocurrencies, period = '496d', interval = '1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dcbcd607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing each indicator in separately dataframe\n",
    "df_open = data['Open'].reset_index()\n",
    "\n",
    "df_close = data['Close'].reset_index()\n",
    "\n",
    "df_adj_close = data['Adj Close'].reset_index()\n",
    "\n",
    "df_high = data['High'].reset_index()\n",
    "\n",
    "df_low = data['Low'].reset_index()\n",
    "\n",
    "df_volume = data['Volume'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "653ee2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "\n",
    "for currency in list_of_currencys:\n",
    "    \n",
    "    df[currency] = pd.DataFrame()\n",
    "\n",
    "    #retrieving open price\n",
    "    df1 = df_open[['Date',currency]].copy()\n",
    "    #filtering only non-null records\n",
    "    df1 = df1[~df1[currency].isnull()].copy()\n",
    "    #renaming column ETH-USD to open, which means the Open price for the currency\n",
    "    df1.rename(columns={currency: \"open\"}, inplace=True)\n",
    "\n",
    "    #retrieving close price\n",
    "    df2 = df_close[['Date',currency]]\n",
    "    #filtering only non-null records\n",
    "    df2 = df2[~df2[currency].isnull()].copy()\n",
    "    #renaming column ETH-USD to close, which means the Open price for the currency\n",
    "    df2.rename(columns={currency: \"close\"}, inplace=True)\n",
    "\n",
    "    #retrieving adj_close price\n",
    "    df3 = df_adj_close[['Date',currency]]\n",
    "    #filtering only non-null records\n",
    "    df3 = df3[~df3[currency].isnull()].copy()\n",
    "    #renaming column ETH-USD to adj_close, which means the adj_close price for the currency\n",
    "    df3.rename(columns={currency: \"adj_close\"}, inplace=True)\n",
    "\n",
    "    #retrieving highest price\n",
    "    df4 = df_high[['Date',currency]]\n",
    "    #filtering only non-null records\n",
    "    df4 = df4[~df4[currency].isnull()].copy()\n",
    "    #renaming column ETH-USD to high, which means the highest price for the currency\n",
    "    df4.rename(columns={currency: \"high\"}, inplace=True)\n",
    "\n",
    "    #retrieving lowest price\n",
    "    df5 = df_low[['Date',currency]]\n",
    "    #filtering only non-null records\n",
    "    df5 = df5[~df5[currency].isnull()].copy()\n",
    "    #renaming column ETH-USD to df5, which means the lowest price for the currency\n",
    "    df5.rename(columns={currency: \"low\"}, inplace=True)\n",
    "\n",
    "    #retrieving Volume\n",
    "    df6 = df_volume[['Date',currency]]\n",
    "    #filtering only non-null records\n",
    "    df6 = df6[~df6[currency].isnull()].copy()\n",
    "    #renaming column ETH-USD to Volume, which means the Volume for the currency\n",
    "    df6.rename(columns={currency: \"volume\"}, inplace=True)\n",
    "    \n",
    "    name=str(currency)\n",
    "\n",
    "    #merging dataframes into a single dataframe\n",
    "    temp_2 = pd.merge(df1, df2, left_on='Date', right_on='Date', how='left')\n",
    "    temp_3 = pd.merge(temp_2, df3, left_on='Date', right_on='Date', how='left')\n",
    "    temp_4 = pd.merge(temp_3, df4, left_on='Date', right_on='Date', how='left')\n",
    "    temp_5 = pd.merge(temp_4, df5, left_on='Date', right_on='Date', how='left')\n",
    "    temp_6 = pd.merge(temp_5, df6, left_on='Date', right_on='Date', how='left')    \n",
    "    df[currency] = temp_6.copy()\n",
    "    df[currency]['Date'] = pd.to_datetime(df[currency]['Date'])\n",
    "    df[currency]['volume'] = df[currency]['volume'].astype('Int64')\n",
    "    \n",
    "    #Adding Three new rows to the dataset\n",
    "    df[currency] = df[currency].append(\n",
    "        pd.DataFrame({'Date': pd.date_range(start=df[currency].Date.iloc[-1], periods=4, freq='D', closed='right')}))\n",
    "    df[currency].reset_index(inplace=True,drop=True)\n",
    "\n",
    "    #Feature Engineering\n",
    "    df[currency]['year'] = pd.DatetimeIndex(df[currency]['Date']).year\n",
    "    df[currency]['quarter'] = pd.DatetimeIndex(df[currency]['Date']).quarter\n",
    "    df[currency]['month'] = pd.DatetimeIndex(df[currency]['Date']).month\n",
    "    df[currency]['week_number_year'] = pd.DatetimeIndex(df[currency]['Date']).week\n",
    "    df[currency]['day_of_the_week'] = pd.DatetimeIndex(df[currency]['Date']).weekday\n",
    "    df[currency]['day'] = pd.DatetimeIndex(df[currency]['Date']).day "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b121989",
   "metadata": {},
   "source": [
    "#### Creating the Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a8c0b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "for currency in list_of_currencys:    \n",
    "    df[currency]['target_close'] = df[currency]['close']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c4267b",
   "metadata": {},
   "source": [
    "#### Shifting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f9ea8b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for currency in list_of_currencys:\n",
    "    df_temp_shift = df[currency][['open', 'close', 'adj_close', 'high', 'low', 'volume']].shift(+3)\n",
    "    df_temp_target = df[currency][['Date','year','quarter','month','week_number_year','day_of_the_week','day','target_close']]\n",
    "    df_temp_final = pd.concat([df_temp_shift,df_temp_target], axis = 1)\n",
    "    #df[currency] = df_temp_final\n",
    "    df[currency] = df_temp_final.iloc[3:, :]\n",
    "    df[currency].reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca0f3ab",
   "metadata": {},
   "source": [
    "#### Creating new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5fd13777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preserving the original datasets\n",
    "df_original = {}\n",
    "for currency in list_of_currencys:    \n",
    "    df_original[currency] = df[currency].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ebf07bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Technical Analysis Features\n",
    "for currency in list_of_currencys:    \n",
    "    ta.add_all_ta_features(df[currency], \"open\", \"high\", \"low\", \"close\", \"volume\", fillna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9c5a7068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the features trend_psar_up and trend_psar_down due to the quantity of NaN values\n",
    "for currency in list_of_currencys:    \n",
    "    df[currency].drop(['trend_psar_up','trend_psar_down'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5344f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the types of volume_adi and volume_obv from object to float64\n",
    "for currency in list_of_currencys:    \n",
    "    df[currency] = df[currency].astype({'volume_adi':'float64','volume_obv':'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "faafc9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the missing NaN values from the new features\n",
    "\n",
    "list_columns_to_drop_NaN = df['ADA-USD'].columns.tolist()\n",
    "list_columns_to_drop_NaN.remove('target_close')\n",
    "\n",
    "for currency in list_of_currencys:    \n",
    "    df[currency].dropna(axis=0, how='any', subset=list_columns_to_drop_NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9fc5b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseting indexes and Checking new features\n",
    "for currency in list_of_currencys:\n",
    "    df[currency].reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27395a20",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f4cc15ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating copies of the datasets for the purpose of feature selection\n",
    "df_FS = {}\n",
    "for currency in list_of_currencys:    \n",
    "    df_FS[currency] = df[currency].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ca400c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Missing Values in the target (last three rows - new dates to be predicted)\n",
    "for currency in list_of_currencys:    \n",
    "    df_FS[currency].dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3e3e53c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterating the minimun date to define the initial date for train datasets\n",
    "dt_imin = []\n",
    "for currency in list_of_currencys:    \n",
    "    dt_imin.append(df_FS[currency]['Date'].min())\n",
    "dt_min = min(dt_imin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "295add54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterating the maximum date to define the size of the split \n",
    "dt_imax = []\n",
    "for currency in list_of_currencys:    \n",
    "    dt_imax.append(df_FS[currency]['Date'].max())\n",
    "dt_max = min(dt_imax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "298d3656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates the date interval - size of the series\n",
    "date_interval = (dt_max - dt_min) / np.timedelta64(1,'D')\n",
    "\n",
    "#measuring the split size\n",
    "split_size = date_interval*0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5dae44be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates the split date\n",
    "split_date = dt_min + datetime.timedelta(days=split_size)\n",
    "split_date = split_date.strftime('%Y-%m-%d')\n",
    "\n",
    "#calculates the initial date\n",
    "init_date = dt_min.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a09ac601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the features for each currency based on the RFE feature selection\n",
    "feat_ada = ['momentum_kama']\n",
    "\n",
    "feat_atom = ['volatility_bbm', 'trend_ema_slow', 'trend_visual_ichimoku_a']\n",
    "\n",
    "feat_avax = ['volatility_bbl', 'volatility_kcl', 'volatility_dcl', 'volatility_dch', 'volatility_dcm', \n",
    "             'trend_ema_fast', 'trend_ichimoku_a', 'trend_ichimoku_b', 'momentum_tsi', 'momentum_kama']\n",
    "\n",
    "feat_axs = ['close', 'adj_close', 'volume_vwap', 'volatility_kcl', 'trend_macd_signal', 'trend_ema_slow', 'others_cr']\n",
    "\n",
    "feat_luna = ['close']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01916a1a",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"ml_modeling\">\n",
    "    \n",
    "# 7.0 Machine Learning Model and Assessment\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd915e",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"linear\">\n",
    "    \n",
    "## Linear Regression\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3fdb6291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Using LR to predict results for AVAX-USD\n",
    "df_pred = {}\n",
    "summary_LR = pd.DataFrame(index=['New_pred_1','New_pred_2'])\n",
    "\n",
    "#Dataset splitting parameters\n",
    "initial_Date = init_date\n",
    "splitting_Date= split_date\n",
    "\n",
    "for currency in list_of_currencys:\n",
    "    \n",
    "    # List of features to be used\n",
    "    feat_list = feat_avax\n",
    "\n",
    "    # Splitting the dataset\n",
    "    X = df[currency][feat_list]\n",
    "    y = df[currency]['target_close']\n",
    "    initial_index = df[currency].index[df[currency]['Date'] == initial_Date].tolist()\n",
    "    splitt_index = df[currency].index[df[currency]['Date'] == splitting_Date].tolist()    \n",
    "    X_train = X[initial_index[0]:splitt_index[0]]\n",
    "    X_val = X[splitt_index[0]:-3]\n",
    "    y_train = y[initial_index[0]:splitt_index[0]]\n",
    "    y_val = y[splitt_index[0]:-3]\n",
    "    X_new_pred = X[-3:]\n",
    "    \n",
    "#     # Splitting the dataset - classic approach\n",
    "#     X = df[currency].drop(['Date','target_close'], axis = 1)\n",
    "#     y = df[currency]['target_close']\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=0.1, random_state=0, stratify=None, shuffle=False)\n",
    "\n",
    "    #Training the model and running the predictions\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    model_pred = model.predict(X_val)\n",
    "    model_pred_df = pd.DataFrame(data=model_pred, index=X_val.index, columns=['pred'])\n",
    "    \n",
    "    #Running predictions for the training dataset for overfitting checking purpose\n",
    "    model_pred_train = model.predict(X_train)\n",
    "    model_pred_train_df = pd.DataFrame(data=model_pred_train, index=X_train.index, columns=['pred'])\n",
    "    model_pred_train_df = pd.concat([df[currency],model_pred_train_df], axis = 1)\n",
    "    \n",
    "    # Predicting the new data\n",
    "    model_new_pred = model.predict(X_new_pred)\n",
    "    model_new_pred_df = pd.DataFrame(data=model_new_pred, index=X_new_pred.index, columns=['pred'])\n",
    "    model_new_pred_df = pd.concat([df[currency],model_new_pred_df], axis = 1)\n",
    "    \n",
    "    \n",
    "    #RMSE and R-squared\n",
    "    rmse_val = np.sqrt(MSE(y_val,model_pred))\n",
    "    mape_val = MAPE(y_val,model_pred)\n",
    "    rmse_train = np.sqrt(MSE(y_train,model_pred_train))\n",
    "    mape_train = MAPE(y_train,model_pred_train)\n",
    "\n",
    "    #Concatenating the predictions to the original Dataset\n",
    "    df_pred[currency] = pd.concat([df[currency],model_pred_df], axis = 1)\n",
    "\n",
    "    \n",
    "    summary_LR[currency] = [round(model_new_pred_df[-3:-2]['pred'].tolist()[0],2),\n",
    "                            round(model_new_pred_df[-2:-1]['pred'].tolist()[0],2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7642dd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the predictions from Linear Regression\n",
    "lr_predictions = summary_LR['AVAX-USD'].reset_index(drop=True)\n",
    "\n",
    "#calling the predictions from ARIMA\n",
    "df_arima = df_pred_final.reset_index(drop=True)\n",
    "\n",
    "#storing the predictions in result_a\n",
    "result_a = pd.concat([df_arima, lr_predictions], axis=1)\n",
    "\n",
    "#storing the validation predictions for the chosen currencies\n",
    "lr_avax = df_pred['AVAX-USD'][['Date','target_close']][-10:-3]\n",
    "lr_avax = lr_avax.rename(columns={'target_close': 'AVAX-USD'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7746d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using LR to predict results for LUNA1-USD\n",
    "df_pred = {}\n",
    "summary_LR = pd.DataFrame(index=['New_pred_1','New_pred_2'])\n",
    "\n",
    "#Dataset splitting parameters\n",
    "initial_Date = init_date\n",
    "splitting_Date= split_date\n",
    "\n",
    "for currency in list_of_currencys:\n",
    "    \n",
    "    # List of features to be used\n",
    "    feat_list = feat_luna\n",
    "\n",
    "    # Splitting the dataset\n",
    "    X = df[currency][feat_list]\n",
    "    y = df[currency]['target_close']\n",
    "    initial_index = df[currency].index[df[currency]['Date'] == initial_Date].tolist()\n",
    "    splitt_index = df[currency].index[df[currency]['Date'] == splitting_Date].tolist()    \n",
    "    X_train = X[initial_index[0]:splitt_index[0]]\n",
    "    X_val = X[splitt_index[0]:-3]\n",
    "    y_train = y[initial_index[0]:splitt_index[0]]\n",
    "    y_val = y[splitt_index[0]:-3]\n",
    "    X_new_pred = X[-3:]\n",
    "    \n",
    "#     # Splitting the dataset - classic approach\n",
    "#     X = df[currency].drop(['Date','target_close'], axis = 1)\n",
    "#     y = df[currency]['target_close']\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=0.1, random_state=0, stratify=None, shuffle=False)\n",
    "\n",
    "    #Training the model and running the predictions\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    model_pred = model.predict(X_val)\n",
    "    model_pred_df = pd.DataFrame(data=model_pred, index=X_val.index, columns=['pred'])\n",
    "    \n",
    "    #Running predictions for the training dataset for overfitting checking purpose\n",
    "    model_pred_train = model.predict(X_train)\n",
    "    model_pred_train_df = pd.DataFrame(data=model_pred_train, index=X_train.index, columns=['pred'])\n",
    "    model_pred_train_df = pd.concat([df[currency],model_pred_train_df], axis = 1)\n",
    "    \n",
    "    # Predicting the new data\n",
    "    model_new_pred = model.predict(X_new_pred)\n",
    "    model_new_pred_df = pd.DataFrame(data=model_new_pred, index=X_new_pred.index, columns=['pred'])\n",
    "    model_new_pred_df = pd.concat([df[currency],model_new_pred_df], axis = 1)\n",
    "    \n",
    "    \n",
    "    #RMSE and R-squared\n",
    "    rmse_val = np.sqrt(MSE(y_val,model_pred))\n",
    "    mape_val = MAPE(y_val,model_pred)\n",
    "    rmse_train = np.sqrt(MSE(y_train,model_pred_train))\n",
    "    mape_train = MAPE(y_train,model_pred_train)\n",
    "\n",
    "    #Concatenating the predictions to the original Dataset\n",
    "    df_pred[currency] = pd.concat([df[currency],model_pred_df], axis = 1)\n",
    "\n",
    "    \n",
    "    summary_LR[currency] = [round(model_new_pred_df[-3:-2]['pred'].tolist()[0],2),\n",
    "                            round(model_new_pred_df[-2:-1]['pred'].tolist()[0],2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b9acf8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the predictions from Linear Regression\n",
    "lr2_predictions = summary_LR['LUNA1-USD'].reset_index(drop=True)\n",
    "\n",
    "#storing the predictions in result\n",
    "result_b = pd.concat([result_a, lr2_predictions], axis=1)\n",
    "\n",
    "#storing the validation predictions for the chosen currencies \n",
    "lr_luna = df_pred['LUNA1-USD'][['Date','target_close']][-10:-3]\n",
    "lr_luna = lr_luna.rename(columns={'target_close': 'LUNA1-USD'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1609bf29",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"rand_forest\">\n",
    "    \n",
    "## Random Forest\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b917d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = {}\n",
    "summary_RF = pd.DataFrame(index=['New_pred_1','New_pred_2'])\n",
    "\n",
    "#Dataset splitting parameters\n",
    "initial_Date = init_date\n",
    "splitting_Date= split_date\n",
    "\n",
    "for currency in list_of_currencys:\n",
    "    \n",
    "    # List of features to be used\n",
    "    feat_list = feat_ada\n",
    "\n",
    "    # Splitting the dataset\n",
    "    X = df[currency][feat_list]\n",
    "    y = df[currency]['target_close']\n",
    "    initial_index = df[currency].index[df[currency]['Date'] == initial_Date].tolist()\n",
    "    splitt_index = df[currency].index[df[currency]['Date'] == splitting_Date].tolist()    \n",
    "    X_train = X[initial_index[0]:splitt_index[0]]\n",
    "    X_val = X[splitt_index[0]:-3]\n",
    "    y_train = y[initial_index[0]:splitt_index[0]]\n",
    "    y_val = y[splitt_index[0]:-3]\n",
    "    X_new_pred = X[-3:]\n",
    "    \n",
    "#     # Splitting the dataset - classic approach\n",
    "#     X = df[currency].drop(['Date','target_close'], axis = 1)\n",
    "#     y = df[currency]['target_close']\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=0.1, random_state=0, stratify=None, shuffle=False)\n",
    "\n",
    "    #Training the model and running the predictions\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train,y_train)\n",
    "    model_pred = model.predict(X_val)\n",
    "    model_pred_df = pd.DataFrame(data=model_pred, index=X_val.index, columns=['pred'])\n",
    "    \n",
    "    #Running predictions for the training dataset for overfitting checking purpose\n",
    "    model_pred_train = model.predict(X_train)\n",
    "    model_pred_train_df = pd.DataFrame(data=model_pred_train, index=X_train.index, columns=['pred'])\n",
    "    model_pred_train_df = pd.concat([df[currency],model_pred_train_df], axis = 1)\n",
    "    \n",
    "    # Predicting the new data\n",
    "    model_new_pred = model.predict(X_new_pred)\n",
    "    model_new_pred_df = pd.DataFrame(data=model_new_pred, index=X_new_pred.index, columns=['pred'])\n",
    "    model_new_pred_df = pd.concat([df[currency],model_new_pred_df], axis = 1)\n",
    "    \n",
    "    \n",
    "    #RMSE and R-squared\n",
    "    rmse_val = np.sqrt(MSE(y_val,model_pred))\n",
    "    mape_val = MAPE(y_val,model_pred)\n",
    "    rmse_train = np.sqrt(MSE(y_train,model_pred_train))\n",
    "    mape_train = MAPE(y_train,model_pred_train)\n",
    "\n",
    "    #Concatenating the predictions to the original Dataset\n",
    "    df_pred[currency] = pd.concat([df[currency],model_pred_df], axis = 1)\n",
    "\n",
    "    summary_RF[currency] = [round(model_new_pred_df[-3:-2]['pred'].tolist()[0],2),\n",
    "                            round(model_new_pred_df[-2:-1]['pred'].tolist()[0],2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "525e9548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the predictions from Random Forest\n",
    "rf_predictions = summary_RF['ADA-USD'].reset_index(drop=True)\n",
    "\n",
    "#storing the predictions in result\n",
    "result_c = pd.concat([result_b, rf_predictions], axis=1)\n",
    "\n",
    "#storing the validation predictions for the chosen currencies\n",
    "rf_ada = df_pred['ADA-USD'][['Date','target_close']][-10:-3]\n",
    "rf_ada = rf_ada.rename(columns={'target_close': 'ADA-USD'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17037bd",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"svm\">\n",
    "    \n",
    "## Support Vector Machines\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "68c2e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = {}\n",
    "summary_SVM = pd.DataFrame(index=['New_pred_1','New_pred_2'])\n",
    "\n",
    "#Dataset splitting parameters\n",
    "initial_Date = init_date\n",
    "splitting_Date= split_date\n",
    "\n",
    "for currency in list_of_currencys:\n",
    "    \n",
    "    # List of features to be used\n",
    "    feat_list = feat_atom\n",
    "\n",
    "    # Splitting the dataset\n",
    "    X = df[currency][feat_list]\n",
    "    y = df[currency]['target_close']\n",
    "    initial_index = df[currency].index[df[currency]['Date'] == initial_Date].tolist()\n",
    "    splitt_index = df[currency].index[df[currency]['Date'] == splitting_Date].tolist()    \n",
    "    X_train = X[initial_index[0]:splitt_index[0]]\n",
    "    X_val = X[splitt_index[0]:-3]\n",
    "    y_train = y[initial_index[0]:splitt_index[0]]\n",
    "    y_val = y[splitt_index[0]:-3]\n",
    "    X_new_pred = X[-3:]\n",
    "    \n",
    "#     # Splitting the dataset - classic approach\n",
    "#     X = df[currency].drop(['Date','target_close'], axis = 1)\n",
    "#     y = df[currency]['target_close']\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=0.1, random_state=0, stratify=None, shuffle=False)\n",
    "\n",
    "    #Training the model and running the predictions\n",
    "    model = svm.SVR()\n",
    "    model.fit(X_train,y_train)\n",
    "    model_pred = model.predict(X_val)\n",
    "    model_pred_df = pd.DataFrame(data=model_pred, index=X_val.index, columns=['pred'])\n",
    "    \n",
    "    #Running predictions for the training dataset for overfitting checking purpose\n",
    "    model_pred_train = model.predict(X_train)\n",
    "    model_pred_train_df = pd.DataFrame(data=model_pred_train, index=X_train.index, columns=['pred'])\n",
    "    model_pred_train_df = pd.concat([df[currency],model_pred_train_df], axis = 1)\n",
    "    \n",
    "    # Predicting the new data\n",
    "    model_new_pred = model.predict(X_new_pred)\n",
    "    model_new_pred_df = pd.DataFrame(data=model_new_pred, index=X_new_pred.index, columns=['pred'])\n",
    "    model_new_pred_df = pd.concat([df[currency],model_new_pred_df], axis = 1)\n",
    "    \n",
    "    \n",
    "    #RMSE and R-squared\n",
    "    rmse_val = np.sqrt(MSE(y_val,model_pred))\n",
    "    mape_val = MAPE(y_val,model_pred)\n",
    "    rmse_train = np.sqrt(MSE(y_train,model_pred_train))\n",
    "    mape_train = MAPE(y_train,model_pred_train)\n",
    "\n",
    "    #Concatenating the predictions to the original Dataset\n",
    "    df_pred[currency] = pd.concat([df[currency],model_pred_df], axis = 1)\n",
    "\n",
    "    summary_SVM[currency] = [round(model_new_pred_df[-3:-2]['pred'].tolist()[0],2),\n",
    "                            round(model_new_pred_df[-2:-1]['pred'].tolist()[0],2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "15633ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the predictions from Random Forest\n",
    "svm_predictions = summary_SVM['ATOM-USD'].reset_index(drop=True)\n",
    "\n",
    "#storing the predictions in result\n",
    "result_d = pd.concat([result_c, svm_predictions], axis=1)\n",
    "\n",
    "#storing the validation predictions for the chosen currencies\n",
    "svm_atom = df_pred['ATOM-USD'][['Date','target_close']][-10:-3]\n",
    "svm_atom = svm_atom.rename(columns={'target_close': 'ATOM-USD'})  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55ff0e5",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"neural\">\n",
    "    \n",
    "## Neural Network Regressor\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fe17712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = {}\n",
    "summary_NNR = pd.DataFrame(index=['New_pred_1','New_pred_2'])\n",
    "\n",
    "#Dataset splitting parameters\n",
    "initial_Date = init_date\n",
    "splitting_Date= split_date\n",
    "\n",
    "for currency in list_of_currencys:\n",
    "    \n",
    "    # List of features to be used\n",
    "    feat_list = feat_axs\n",
    "\n",
    "    # Splitting the dataset\n",
    "    X = df[currency][feat_list]\n",
    "    y = df[currency]['target_close']\n",
    "    initial_index = df[currency].index[df[currency]['Date'] == initial_Date].tolist()\n",
    "    splitt_index = df[currency].index[df[currency]['Date'] == splitting_Date].tolist()    \n",
    "    X_train = X[initial_index[0]:splitt_index[0]]\n",
    "    X_val = X[splitt_index[0]:-3]\n",
    "    y_train = y[initial_index[0]:splitt_index[0]]\n",
    "    y_val = y[splitt_index[0]:-3]\n",
    "    X_new_pred = X[-3:]\n",
    "    \n",
    "#     # Splitting the dataset - classic approach\n",
    "#     X = df[currency].drop(['Date','target_close'], axis = 1)\n",
    "#     y = df[currency]['target_close']\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=0.1, random_state=0, stratify=None, shuffle=False)\n",
    "\n",
    "    #Training the model and running the predictions\n",
    "    model = MLPRegressor(hidden_layer_sizes=(100,100,100,100,100,100),max_iter=100,learning_rate_init=0.0001,learning_rate='adaptive')\n",
    "    model.fit(X_train,y_train)\n",
    "    model_pred = model.predict(X_val)\n",
    "    model_pred_df = pd.DataFrame(data=model_pred, index=X_val.index, columns=['pred'])\n",
    "    \n",
    "    #Running predictions for the training dataset for overfitting checking purpose\n",
    "    model_pred_train = model.predict(X_train)\n",
    "    model_pred_train_df = pd.DataFrame(data=model_pred_train, index=X_train.index, columns=['pred'])\n",
    "    model_pred_train_df = pd.concat([df[currency],model_pred_train_df], axis = 1)\n",
    "    \n",
    "    # Predicting the new data\n",
    "    model_new_pred = model.predict(X_new_pred)\n",
    "    model_new_pred_df = pd.DataFrame(data=model_new_pred, index=X_new_pred.index, columns=['pred'])\n",
    "    model_new_pred_df = pd.concat([df[currency],model_new_pred_df], axis = 1)\n",
    "    \n",
    "    \n",
    "    #RMSE and R-squared\n",
    "    rmse_val = np.sqrt(MSE(y_val,model_pred))\n",
    "    mape_val = MAPE(y_val,model_pred)\n",
    "    rmse_train = np.sqrt(MSE(y_train,model_pred_train))\n",
    "    mape_train = MAPE(y_train,model_pred_train)\n",
    "\n",
    "    #Concatenating the predictions to the original Dataset\n",
    "    df_pred[currency] = pd.concat([df[currency],model_pred_df], axis = 1)\n",
    "\n",
    "    summary_NNR[currency] = [round(model_new_pred_df[-3:-2]['pred'].tolist()[0],2),\n",
    "                            round(model_new_pred_df[-2:-1]['pred'].tolist()[0],2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fad955d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the predictions from Random Forest\n",
    "nnr_predictions = summary_NNR['AXS-USD'].reset_index(drop=True)\n",
    "\n",
    "#storing the predictions for D+1 and D+2 in the dataframe df_pred_dashboard\n",
    "df_pred_final = pd.concat([result_d, nnr_predictions], axis=1)\n",
    "\n",
    "#storing the validation predictions for the chosen currencies\n",
    "nnr_axs = df_pred['AXS-USD'][['Date','target_close']][-10:-3]\n",
    "nnr_axs = nnr_axs.rename(columns={'target_close': 'AXS-USD'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cbbfc84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the validation predictions for the chosen currencies\n",
    "temp_val_a = pd.merge(df_val_final, lr_avax, left_on='Date', right_on='Date', how='left')\n",
    "temp_val_b = pd.merge(temp_val_a, lr_luna, left_on='Date', right_on='Date', how='left')\n",
    "temp_val_c = pd.merge(temp_val_b, rf_ada, left_on='Date', right_on='Date', how='left')\n",
    "temp_val_d = pd.merge(temp_val_c, svm_atom, left_on='Date', right_on='Date', how='left')\n",
    "temp_val_final = pd.merge(temp_val_d, nnr_axs, left_on='Date', right_on='Date', how='left')\n",
    "\n",
    "#filling missing values with the mean for each column\n",
    "fill_mean = lambda col : col.fillna(col.mean())\n",
    "df_val_final = temp_val_final.apply(fill_mean, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2a9f2983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>LINK-USD</th>\n",
       "      <th>MATIC-USD</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>SOL-USD</th>\n",
       "      <th>AVAX-USD</th>\n",
       "      <th>LUNA1-USD</th>\n",
       "      <th>ADA-USD</th>\n",
       "      <th>ATOM-USD</th>\n",
       "      <th>AXS-USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>29800.632089</td>\n",
       "      <td>7.209214</td>\n",
       "      <td>0.701169</td>\n",
       "      <td>2011.888513</td>\n",
       "      <td>51.188797</td>\n",
       "      <td>29.026232</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.512605</td>\n",
       "      <td>11.132798</td>\n",
       "      <td>20.923748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>28274.342732</td>\n",
       "      <td>6.439757</td>\n",
       "      <td>0.595602</td>\n",
       "      <td>1888.637531</td>\n",
       "      <td>46.128928</td>\n",
       "      <td>29.025648</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.521224</td>\n",
       "      <td>11.082132</td>\n",
       "      <td>21.247337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>27753.700020</td>\n",
       "      <td>6.112968</td>\n",
       "      <td>0.543988</td>\n",
       "      <td>1780.631535</td>\n",
       "      <td>41.077769</td>\n",
       "      <td>27.225376</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.513877</td>\n",
       "      <td>10.739818</td>\n",
       "      <td>20.898247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>28129.833892</td>\n",
       "      <td>6.223086</td>\n",
       "      <td>0.569707</td>\n",
       "      <td>1812.436500</td>\n",
       "      <td>42.066936</td>\n",
       "      <td>23.550030</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.480883</td>\n",
       "      <td>9.643618</td>\n",
       "      <td>19.561852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>27495.929277</td>\n",
       "      <td>5.998551</td>\n",
       "      <td>0.574621</td>\n",
       "      <td>1764.853387</td>\n",
       "      <td>40.429657</td>\n",
       "      <td>22.418623</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.455507</td>\n",
       "      <td>9.252514</td>\n",
       "      <td>18.198242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>26699.953242</td>\n",
       "      <td>5.602997</td>\n",
       "      <td>0.558048</td>\n",
       "      <td>1709.550838</td>\n",
       "      <td>38.299471</td>\n",
       "      <td>22.749695</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.455911</td>\n",
       "      <td>9.414568</td>\n",
       "      <td>18.242544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>26598.498519</td>\n",
       "      <td>5.593469</td>\n",
       "      <td>0.584127</td>\n",
       "      <td>1717.542988</td>\n",
       "      <td>38.646213</td>\n",
       "      <td>25.665934</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.490001</td>\n",
       "      <td>10.210908</td>\n",
       "      <td>19.845328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       BTC-USD  LINK-USD  MATIC-USD      ETH-USD    SOL-USD  \\\n",
       "0 2022-05-23  29800.632089  7.209214   0.701169  2011.888513  51.188797   \n",
       "1 2022-05-24  28274.342732  6.439757   0.595602  1888.637531  46.128928   \n",
       "2 2022-05-25  27753.700020  6.112968   0.543988  1780.631535  41.077769   \n",
       "3 2022-05-26  28129.833892  6.223086   0.569707  1812.436500  42.066936   \n",
       "4 2022-05-27  27495.929277  5.998551   0.574621  1764.853387  40.429657   \n",
       "5 2022-05-28  26699.953242  5.602997   0.558048  1709.550838  38.299471   \n",
       "6 2022-05-29  26598.498519  5.593469   0.584127  1717.542988  38.646213   \n",
       "\n",
       "    AVAX-USD  LUNA1-USD   ADA-USD   ATOM-USD    AXS-USD  \n",
       "0  29.026232   0.000160  0.512605  11.132798  20.923748  \n",
       "1  29.025648   0.000177  0.521224  11.082132  21.247337  \n",
       "2  27.225376   0.000182  0.513877  10.739818  20.898247  \n",
       "3  23.550030   0.000139  0.480883   9.643618  19.561852  \n",
       "4  22.418623   0.000119  0.455507   9.252514  18.198242  \n",
       "5  22.749695   0.000121  0.455911   9.414568  18.242544  \n",
       "6  25.665934   0.000150  0.490001  10.210908  19.845328  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final validation dataset to be used on Dashboard\n",
    "df_val_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fbf2629a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>LINK-USD</th>\n",
       "      <th>MATIC-USD</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>SOL-USD</th>\n",
       "      <th>AVAX-USD</th>\n",
       "      <th>LUNA1-USD</th>\n",
       "      <th>ADA-USD</th>\n",
       "      <th>ATOM-USD</th>\n",
       "      <th>AXS-USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>25531.469277</td>\n",
       "      <td>4.847741</td>\n",
       "      <td>0.506455</td>\n",
       "      <td>1603.798802</td>\n",
       "      <td>31.533355</td>\n",
       "      <td>21.34</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.21</td>\n",
       "      <td>11.97</td>\n",
       "      <td>17.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>24830.131260</td>\n",
       "      <td>4.384801</td>\n",
       "      <td>0.445702</td>\n",
       "      <td>1472.218447</td>\n",
       "      <td>25.654512</td>\n",
       "      <td>21.42</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.21</td>\n",
       "      <td>11.89</td>\n",
       "      <td>17.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       BTC-USD  LINK-USD  MATIC-USD      ETH-USD    SOL-USD  \\\n",
       "0 2022-05-30  25531.469277  4.847741   0.506455  1603.798802  31.533355   \n",
       "1 2022-05-31  24830.131260  4.384801   0.445702  1472.218447  25.654512   \n",
       "\n",
       "   AVAX-USD  LUNA1-USD  ADA-USD  ATOM-USD  AXS-USD  \n",
       "0     21.34       0.92     1.21     11.97    17.79  \n",
       "1     21.42       0.92     1.21     11.89    17.83  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final predictions dataset to be used on Dashboard\n",
    "df_pred_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028333e9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "__FIM__ <br>\n",
    "     \n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
